# Truthset

This directory contains scripts relevant to generation, evaluation, and abritration of truthsets used in benchmarking.

## Truthset generation

The truthset is a manually curated resource generated by clinical analysts who are manually reviewing literature 
relevant to potential disease-genes. The process by which genes, candidate papers, and papers requiring in-depth review 
were selected is described in the benchmarking protocol. The review process for paper relevance and content extraction
is also described in this protocol.

Currently, genes, candidate papers, and papers requiring in-depth review are selected using the notebook 
`sandbox/ash/gencc_truth_set.ipynb`.

The result of this process is a spreadsheet of manual curations that must be pre-processed before it can be leveraged
for benchmarking purposes. This spreadsheet is currently stored at 
[this location](https://docs.google.com/spreadsheets/d/1dNtWYQKAIW8sLPNjr0myJSQSuPyRErpu-tyGixZVfTs/edit?usp=drive_link)
(access must be requested) and the latest version of this spreadsheet needs to be localized to the machine being used
for preprocessing before the truthset generation script can be run.

Additionally the list of genes reviewed during truthset curation has been split into two groups, `train` and `test`. 
The `train` genes are intended to be used for ongoing pipeline development, and thus results based on this group should
be interpreted carefully as the risk of overfitting is increased. The genes in `test` have only been analyzed with the 
pipeline codebase at a specified state (see [v1.0.0-pre-testset](https://github.com/jeremiahwander/ev-agg-exp/releases/tag/v1.0.0-pre-testset))
and should thus be representative of pipeline performance on previously unseen examples. A file describing group these 
assignments is available in the repository at `data/v1/group_assignments.tsv`.

Given the source spreadsheet and group assignments file, one can then generate the truthset files that will be used in
subsequent benchmarking with the following command, executed from the repository root.

```bash
python scripts/truthset/generate_manual_truth_set_v1.py
```

Successful execution of this script will cause the generation (or update) of the following files.

- evidence_test_v1.tsv
- evidence_train_v1.tsv
- papers_test_v1.tsv
- papers_train_v1.tsv

The two files of the form `evidence_*` are machine-readable tables containing the manually curated content extracted
from a subset of papers from the genes in the corresponding group [`train`, `test`]. The two files of the form 
`papers_*` are machine-readable tables containing the manual relevance classification of all papers reviewed from the
genes in the corresponding group [`train`, `test`].

## Truthset assessment

After generation of the truthset, one can perform brief quality assessment by interactively running 
`scripts/truthset/assess_manual_truth_set_v1.py`. This script generates figures and does not currently write them to 
file, so it must be run interactively in order to view the complete output.



